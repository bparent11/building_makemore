{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniconda\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the names.txt file from github\n",
    "\n",
    "import requests\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le fichier a été téléchargé avec succès.\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with open(\"names.txt\", \"w\") as file:\n",
    "        file.write(response.text)\n",
    "    print(\"Le fichier a été téléchargé avec succès.\")\n",
    "else:\n",
    "    print(\"Le téléchargement du fichier a échoué\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response.text.splitlines() allows us to directly get the list but in the case I'm working offline, I download locally the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"names.txt\", \"r\") as file:\n",
    "#    raw_names = file.read()\n",
    "\n",
    "raw_names = open('names.txt', 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = raw_names.splitlines()\n",
    "print(len(names))\n",
    "names[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the vocabulary of characters and mapping it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = sorted(list(set(''.join(name for name in names))))\n",
    "char_to_int = {char:i+1 for i, char in enumerate(characters)}\n",
    "char_to_int[\".\"] = 0 #special character to begin of put an end to a sequence\n",
    "int_to_char = {i:char for char, i in char_to_int.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size = 4 # number of precedents char to take into account\n",
    "\n",
    "def build_dataset(words, context_size):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for name in names:\n",
    "        context = [0] * context_size\n",
    "\n",
    "        for char in name + '.':\n",
    "            idx = char_to_int[char]\n",
    "            X.append(context)\n",
    "            y.append(idx)\n",
    "\n",
    "            #print(f\"{''.join(int_to_char[i] for i in context)}\")\n",
    "\n",
    "            context = context[1:] + [idx]\n",
    "\n",
    "    X, y = torch.tensor(X), torch.tensor(y)\n",
    "    print(f\"X.shape : {X.shape}, y.shape : {y.shape}\")\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape : torch.Size([228146, 4]), y.shape : torch.Size([228146])\n"
     ]
    }
   ],
   "source": [
    "X, y = build_dataset(names, context_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "random\n",
    "\n",
    "n1 = int(0.8 * X.shape[0])\n",
    "n2 = int(0.9 * X.shape[0])\n",
    "\n",
    "Xtr, Xval, Xtst = X.tensor_split((n1, n2), dim=0)\n",
    "ytr, yval, ytst = y.tensor_split((n1, n2), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtr.shape : torch.Size([182516, 4]), Xval.shape : torch.Size([22815, 4]), Xtst.shape : torch.Size([22815, 4])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Xtr.shape : {Xtr.shape}, Xval.shape : {Xval.shape}, Xtst.shape : {Xtst.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing the MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(42) # for reproductibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.rand([27, 2], generator=g) # characters to vectors\n",
    "W1 = torch.rand([4*2, 100], generator=g) # putting in the MLP 4 characters and each one of them has 2 dimensionnal vector associated\n",
    "b1 = torch.rand([100], generator=g)\n",
    "W2 = torch.rand([100, 27], generator=g)\n",
    "b2 = torch.rand([27], generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([228146, 4, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([228146, 8])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X]\n",
    "print(emb.shape)\n",
    "emb.view(-1, 8).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146, 100])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step1 = F.tanh(emb.view(-1, 8) @ W1 + b1)\n",
    "step1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146, 27])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step2 = step1 @ W2 + b2\n",
    "step2.shape # just before applying softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
