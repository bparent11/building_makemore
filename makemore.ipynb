{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the names.txt file from github\n",
    "\n",
    "import requests\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le fichier a été téléchargé avec succès.\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with open(\"names.txt\", \"w\") as file:\n",
    "        file.write(response.text)\n",
    "    print(\"Le fichier a été téléchargé avec succès.\")\n",
    "else:\n",
    "    print(\"Le téléchargement du fichier a échoué\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response.text.splitlines() allows us to directly get the list but in the case I'm working offline, I download locally the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"names.txt\", \"r\") as file:\n",
    "#    raw_names = file.read()\n",
    "\n",
    "raw_names = open('names.txt', 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = raw_names.splitlines()\n",
    "print(len(names))\n",
    "names[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the vocabulary of characters and mapping it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = sorted(list(set(''.join(name for name in names))))\n",
    "char_to_int = {char:i+1 for i, char in enumerate(characters)}\n",
    "char_to_int[\".\"] = 0 #special character to begin of put an end to a sequence\n",
    "int_to_char = {i:char for char, i in char_to_int.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size = 4 # number of precedents char to take into account\n",
    "\n",
    "def build_dataset(words, context_size):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for name in names:\n",
    "        context = [0] * context_size\n",
    "\n",
    "        for char in name + '.':\n",
    "            idx = char_to_int[char]\n",
    "            X.append(context)\n",
    "            y.append(idx)\n",
    "\n",
    "            #print(f\"{''.join(int_to_char[i] for i in context)}\")\n",
    "\n",
    "            context = context[1:] + [idx]\n",
    "\n",
    "    X, y = torch.tensor(X), torch.tensor(y)\n",
    "    print(f\"X.shape : {X.shape}, y.shape : {y.shape}\")\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape : torch.Size([228146, 4]), y.shape : torch.Size([228146])\n"
     ]
    }
   ],
   "source": [
    "X, y = build_dataset(names, context_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "random\n",
    "\n",
    "n1 = int(0.8 * X.shape[0])\n",
    "n2 = int(0.9 * X.shape[0])\n",
    "\n",
    "Xtr, Xval, Xtst = X.tensor_split((n1, n2), dim=0)\n",
    "ytr, yval, ytst = y.tensor_split((n1, n2), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtr.shape : torch.Size([182516, 4]), Xval.shape : torch.Size([22815, 4]), Xtst.shape : torch.Size([22815, 4])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Xtr.shape : {Xtr.shape}, Xval.shape : {Xval.shape}, Xtst.shape : {Xtst.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing the MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(42) # for reproductibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.rand([27, 2], generator=g) # characters to vectors\n",
    "W1 = torch.rand([4*2, 100], generator=g) # putting in the MLP 4 characters and each one of them has 2 dimensionnal vector associated\n",
    "b1 = torch.rand(100, generator=g)\n",
    "W2 = torch.rand([100, 27], generator=g)\n",
    "b2 = torch.rand(27, generator=g)\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "\n",
    "for p in parameters:\n",
    "    p.requires_grad = True # we need to give this information to torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3681"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of parameters in total\n",
    "\n",
    "sum(p.nelement() for p in parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(Xtrain, ytrain, iterations, batch_size):\n",
    "    loss_i = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "\n",
    "        # batch construction\n",
    "        batch_idx = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "\n",
    "        # forward pass\n",
    "        emb = C[X[batch_idx]]\n",
    "        h = F.tanh(emb.view(-1, 8) @ W1 + b1)\n",
    "        logits = h @ W2 + b2\n",
    "\n",
    "        loss = F.cross_entropy(logits, ytrain[batch_idx])\n",
    "\n",
    "        # backward pass\n",
    "        for p in parameters:\n",
    "            p.grad = None # reset the gradient to avoid accumulation\n",
    "        loss.backward()\n",
    "\n",
    "        # update\n",
    "        for p in parameters:\n",
    "            p.data += -0.1*p.grad\n",
    "        \n",
    "    loss_i.append(loss.item())\n",
    "\n",
    "    return loss_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(Xvalid, yvalid):   \n",
    "    emb = C[Xvalid]\n",
    "    h = F.tanh(emb.view(-1, 8) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "\n",
    "    val_loss = F.cross_entropy(logits, yvalid)\n",
    "    \n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.7550342082977295]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training(Xtrain=Xtr, ytrain=ytr, iterations=10000, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5412, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation(Xvalid=Xval, yvalid=yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
